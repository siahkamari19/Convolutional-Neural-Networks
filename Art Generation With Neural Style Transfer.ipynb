{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport scipy.io\nimport scipy.misc\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom PIL import Image\nfrom nst_utils import *\nimport numpy as np\nimport tensorflow as tf\n\n%matplotlib inline\n\nmodel = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\nprint(model)\n\ncontent_image = scipy.misc.imread(\"images/louvre.jpg\")\nimshow(content_image)\n\ndef compute_content_cost(a_C, a_G):\n    m, n_H, n_W, n_C =  a_G.get_shape().as_list()\n    a_C_unrolled = tf.transpose(tf.reshape(a_C, [n_H * n_W, n_C]))\n    a_G_unrolled = tf.transpose(tf.reshape(a_G, [n_H * n_W, n_C]))\n    J_content = tf.reduce_sum(tf.square(tf.subtract(a_G_unrolled, a_C_unrolled))) * (1 / (4 * n_H * n_W * n_C)) \n    return J_content\n\ntf.reset_default_graph()\nwith tf.Session() as test:\n    tf.set_random_seed(1)\n    a_C = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n    J_content = compute_content_cost(a_C, a_G)\n    print(\"J_content = \" + str(J_content.eval()))\n    \nstyle_image = scipy.misc.imread(\"images/monet_800600.jpg\")\nimshow(style_image)\n\n\ndef gram_matrix(A):\n    GA = tf.matmul(A, tf.transpose(A))\n    return GA\n\n\ntf.reset_default_graph()\nwith tf.Session() as test:\n    tf.set_random_seed(1)\n    A = tf.random_normal([3, 2*1], mean=1, stddev=4)\n    GA = gram_matrix(A)\n    print(\"GA = \" + str(GA.eval()))\n\n    def compute_layer_style_cost(a_S, a_G):\n    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n    a_S = tf.transpose(tf.reshape(a_S, [n_H * n_W, n_C]))\n    a_G = tf.transpose(tf.reshape(a_G, [n_H * n_W, n_C]))\n    GS = gram_matrix(a_S)\n    GG = gram_matrix(a_G)\n    J_style_layer = (1 / (4 * n_C **2 * (n_H * n_W) **2)) * tf.reduce_sum(tf.square(tf.subtract(GS, GG)))\n    return J_style_layer\n\ntf.reset_default_graph()\nwith tf.Session() as test:\n    tf.set_random_seed(1)\n    a_S = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n    J_style_layer = compute_layer_style_cost(a_S, a_G)\n    print(\"J_style_layer = \" + str(J_style_layer.eval()))\n    \nSTYLE_LAYERS = [\n    ('conv1_1', 0.2),\n    ('conv2_1', 0.2),\n    ('conv3_1', 0.2),\n    ('conv4_1', 0.2),\n    ('conv5_1', 0.2)]\n\ndef compute_style_cost(model, STYLE_LAYERS):\n    J_style = 0\n    for layer_name, coeff in STYLE_LAYERS:\n        out = model[layer_name]\n        a_S = sess.run(out)\n        a_G = out\n        J_style_layer = compute_layer_style_cost(a_S, a_G)\n        J_style += coeff * J_style_layer\n    return J_style\n\ndef total_cost(J_content, J_style, alpha = 10, beta = 40):\n    J = alpha * J_content + beta * J_style\n    return J\n\ntf.reset_default_graph()\nwith tf.Session() as test:\n    np.random.seed(3)\n    J_content = np.random.randn()    \n    J_style = np.random.randn()\n    J = total_cost(J_content, J_style)\n    print(\"J = \" + str(J))\n    \ntf.reset_default_graph()\nsess = tf.InteractiveSession()\n\ncontent_image = scipy.misc.imread(\"images/louvre_small.jpg\")\ncontent_image = reshape_and_normalize_image(content_image)\nstyle_image = scipy.misc.imread(\"images/monet.jpg\")\nstyle_image = reshape_and_normalize_image(style_image)\ngenerated_image = generate_noise_image(content_image)\nimshow(generated_image[0])\n\nmodel = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\n\nsess.run(model['input'].assign(content_image))\nout = model['conv4_2']\na_C = sess.run(out)\na_G = out\n\nJ_content = compute_content_cost(a_C, a_G)\n\nsess.run(model['input'].assign(style_image))\n\nJ_style = compute_style_cost(model, STYLE_LAYERS)\n\nJ = total_cost(J_content, J_style)\n\noptimizer = tf.train.AdamOptimizer(2.0)\n\ntrain_step = optimizer.minimize(J)\n\ndef model_nn(sess, input_image, num_iterations = 200):\n    sess.run(tf.global_variables_initializer())\n    generated_image = sess.run(model['input'].assign(input_image))\n    for i in range(num_iterations):\n        sess.run(train_step)\n        generated_image = sess.run(model['input'])\n        if i%20 == 0:\n            Jt, Jc, Js = sess.run([J, J_content, J_style])\n            print(\"Iteration \" + str(i) + \" :\")\n            print(\"total cost = \" + str(Jt))\n            print(\"content cost = \" + str(Jc))\n            print(\"style cost = \" + str(Js))\n            save_image(\"output/\" + str(i) + \".png\", generated_image)\n    save_image('output/generated_image.jpg', generated_image)\n    return generated_image\n\nmodel_nn(sess, generated_image)\n\n\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}